{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Retrieval: Hierarchical Multi-Modal Search\n",
    "\n",
    "This notebook implements the two-stage hierarchical retrieval system with table-aware routing.\n",
    "\n",
    "**Objectives:**\n",
    "- Stage A: Section-level retrieval\n",
    "- Stage B: Intra-section dense + BM25 hybrid search\n",
    "- Query routing for table-centric questions\n",
    "- Retrieval fusion and reranking\n",
    "- Evidence collection for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'  # Fix OpenMP conflict\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from utils.config import PARSED_DATA_DIR, INDICES_DIR, MODEL_DIR\n",
    "from retrieval.text_chunker import TextChunker\n",
    "from retrieval.embedding_generator import EmbeddingGenerator\n",
    "from retrieval.index_builder import IndexBuilder\n",
    "from retrieval.query_router import QueryRouter\n",
    "from retrieval.hierarchical_retriever import HierarchicalRetriever\n",
    "from retrieval.hybrid_search import HybridSearcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Indices and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading indices and data...\n",
      "Loaded 14810 section vectors\n",
      "Loaded 17706 text chunk vectors\n",
      "Loaded 15838 table sentence vectors\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading indices and data...\")\n",
    "\n",
    "# Load FAISS indices\n",
    "section_index = faiss.read_index(str(INDICES_DIR / \"section_index.faiss\"))\n",
    "text_index = faiss.read_index(str(INDICES_DIR / \"text_index.faiss\"))\n",
    "table_index = faiss.read_index(str(INDICES_DIR / \"table_index.faiss\"))\n",
    "\n",
    "# Load content and metadata\n",
    "with open(INDICES_DIR / \"section_data.pkl\", 'rb') as f:\n",
    "    section_data = pickle.load(f)\n",
    "\n",
    "with open(INDICES_DIR / \"text_data.pkl\", 'rb') as f:\n",
    "    text_data = pickle.load(f)\n",
    "\n",
    "with open(INDICES_DIR / \"table_data.pkl\", 'rb') as f:\n",
    "    table_data = pickle.load(f)\n",
    "\n",
    "# Load index config\n",
    "with open(INDICES_DIR / \"index_config.json\", 'r') as f:\n",
    "    index_config = json.load(f)\n",
    "\n",
    "print(f\"Loaded {section_index.ntotal} section vectors\")\n",
    "print(f\"Loaded {text_index.ntotal} text chunk vectors\")\n",
    "print(f\"Loaded {table_index.ntotal} table sentence vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Retrieval Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-encoder loaded for reranking\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model (same as indexing)\n",
    "embedding_model = SentenceTransformer(index_config['embedding_model'])\n",
    "\n",
    "# Initialize query router\n",
    "query_router = QueryRouter()\n",
    "\n",
    "# Initialize hierarchical retriever\n",
    "hierarchical_retriever = HierarchicalRetriever(\n",
    "    section_index=section_index,\n",
    "    text_index=text_index,\n",
    "    table_index=table_index,\n",
    "    section_data=section_data,\n",
    "    text_data=text_data,\n",
    "    table_data=table_data,\n",
    "    embedding_model=embedding_model\n",
    ")\n",
    "\n",
    "# Initialize hybrid searcher (dense + BM25 fusion)\n",
    "hybrid_searcher = HybridSearcher(\n",
    "    dense_weight=0.7,\n",
    "    bm25_weight=0.3\n",
    ")\n",
    "\n",
    "# Optional: Load cross-encoder for reranking\n",
    "USE_RERANKING = True\n",
    "if USE_RERANKING:\n",
    "    cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    print(\"Cross-encoder loaded for reranking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query Routing: Classify Query Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Query Routing ===\n",
      "\n",
      "Query: Report the YoY change in R&D expense for 2022 to 2024\n",
      "  Type: numeric_table\n",
      "  Table-centric: True\n",
      "  Requires math: True\n",
      "  Confidence: 0.80\n",
      "\n",
      "Query: What is the ratio of long-term debt to equity in 2023?\n",
      "  Type: numeric_table\n",
      "  Table-centric: True\n",
      "  Requires math: True\n",
      "  Confidence: 0.80\n",
      "\n",
      "Query: Which operating segment contributed most to 2024 revenue growth?\n",
      "  Type: numeric_table\n",
      "  Table-centric: True\n",
      "  Requires math: True\n",
      "  Confidence: 0.80\n",
      "\n",
      "Query: Explain the company's business strategy\n",
      "  Type: narrative\n",
      "  Table-centric: False\n",
      "  Requires math: False\n",
      "  Confidence: 0.60\n",
      "\n",
      "Query: What are the main risk factors?\n",
      "  Type: narrative\n",
      "  Table-centric: False\n",
      "  Requires math: False\n",
      "  Confidence: 0.60\n"
     ]
    }
   ],
   "source": [
    "# Test query routing\n",
    "test_queries = [\n",
    "    \"Report the YoY change in R&D expense for 2022 to 2024\",\n",
    "    \"What is the ratio of long-term debt to equity in 2023?\",\n",
    "    \"Which operating segment contributed most to 2024 revenue growth?\",\n",
    "    \"Explain the company's business strategy\",\n",
    "    \"What are the main risk factors?\"\n",
    "]\n",
    "\n",
    "print(\"=== Query Routing ===\")\n",
    "for query in test_queries:\n",
    "    route_info = query_router.route(query)\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(f\"  Type: {route_info['query_type']}\")\n",
    "    print(f\"  Table-centric: {route_info['is_table_centric']}\")\n",
    "    print(f\"  Requires math: {route_info['requires_math']}\")\n",
    "    print(f\"  Confidence: {route_info['confidence']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hierarchical Retrieval: Stage A (Section Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the ratio of long-term debt to equity in 2023?\n",
      "\n",
      "=== Stage A: Top Sections ===\n",
      "1. [APA 2024] Section 1\n",
      "   Score: 0.5384\n",
      "\n",
      "2. [APA 2022] Section 1\n",
      "   Score: 0.5326\n",
      "\n",
      "3. [APA 2023] Section 1\n",
      "   Score: 0.5309\n",
      "\n",
      "4. [CTVA 2024] Section 1\n",
      "   Score: 0.5283\n",
      "\n",
      "5. [TSN 2024] Section 1\n",
      "   Score: 0.5269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Stage A retrieval\n",
    "query = \"What is the ratio of long-term debt to equity in 2023?\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "# Stage A: Retrieve relevant sections\n",
    "top_sections = hierarchical_retriever.retrieve_sections(\n",
    "    query=query,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "print(\"=== Stage A: Top Sections ===\")\n",
    "for i, section_result in enumerate(top_sections):\n",
    "    meta = section_result['metadata']\n",
    "    score = section_result['score']\n",
    "    print(f\"{i+1}. [{meta['ticker']} {meta['fiscal_year']}] {meta['section_title']}\")\n",
    "    print(f\"   Score: {score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hierarchical Retrieval: Stage B (Intra-Section Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stage B: Top Content (Text + Tables) ===\n",
      "Query type: numeric_table\n",
      "\n",
      "1. [TABLE] Score: 6.9865\n",
      "   MTB 2023 - Unknown\n",
      "   Content: : II. Investments in debt securities   None...\n",
      "\n",
      "2. [TABLE] Score: 6.6350\n",
      "   D 2024 - Unknown\n",
      "   Content: LTIP:  Long-term incentive program...\n",
      "\n",
      "3. [TABLE] Score: 4.2281\n",
      "   HCA 2024 - Unknown\n",
      "   Content: :  2023   Ratio   2022   Ratio   2021   Ratio  None None None None None None...\n",
      "\n",
      "4. [TABLE] Score: 4.2263\n",
      "   HCA 2023 - Unknown\n",
      "   Content: :  2022   Ratio   2021   Ratio   2020   Ratio  None None None None None None...\n",
      "\n",
      "5. [TABLE] Score: 3.2434\n",
      "   MKTX 2024 - Unknown\n",
      "   Content: (3): For emerging markets debt, the amount of new issuance is according to J.P. Morgan Markets. The amount of new issuance excludes debt issued by eme...\n",
      "\n",
      "6. [TABLE] Score: 3.0117\n",
      "   KIM 2022 - Unknown\n",
      "   Content: : ● improving debt metrics and upgraded unsecured debt ratings...\n",
      "\n",
      "7. [TABLE] Score: 2.9716\n",
      "   MKTX 2023 - Unknown\n",
      "   Content: (2): For emerging markets debt, ADTV is as measured by the Emerging Markets Trade Association and amount of new issuance is according to J.P. Morgan M...\n",
      "\n",
      "8. [TABLE] Score: 2.8521\n",
      "   WY 2023 - Unknown\n",
      "   Content: : CONSOLIDATED STATEMENT OF CHANGES IN EQUITY 64...\n",
      "\n",
      "9. [TABLE] Score: 0.3781\n",
      "   MKTX 2022 - Unknown\n",
      "   Content: Emerging market debt(2):  21.1    20.8    1.5     437.1    394.9    10.7  ...\n",
      "\n",
      "10. [TABLE] Score: 0.3781\n",
      "   MKTX 2023 - Unknown\n",
      "   Content: Emerging market debt(2):  20.8    20.4    2.0     219.0    541.0    (59.5 ) ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stage B: Hybrid search within selected sections\n",
    "query = \"What is the ratio of long-term debt to equity in 2023?\"\n",
    "route_info = query_router.route(query)\n",
    "\n",
    "# Retrieve with routing\n",
    "results = hierarchical_retriever.retrieve(\n",
    "    query=query,\n",
    "    route_info=route_info,\n",
    "    top_k_sections=5,\n",
    "    top_k_content=10,\n",
    "    use_hybrid=True\n",
    ")\n",
    "\n",
    "print(\"=== Stage B: Top Content (Text + Tables) ===\")\n",
    "print(f\"Query type: {route_info['query_type']}\\n\")\n",
    "\n",
    "for i, result in enumerate(results['content'][:10]):\n",
    "    meta = result['metadata']\n",
    "    content_type = meta['content_type']\n",
    "    score = result['score']\n",
    "    \n",
    "    print(f\"{i+1}. [{content_type.upper()}] Score: {score:.4f}\")\n",
    "    print(f\"   {meta['ticker']} {meta['fiscal_year']} - {meta.get('section', meta.get('section_title', 'N/A'))}\")\n",
    "    print(f\"   Content: {result['content'][:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hybrid Search: Dense + BM25 Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: R&D expense growth 2023 to 2024\n",
      "\n",
      "=== Dense Retrieval Only ===\n",
      "1. [table] Research and development expense:   109,181    87,581    219,112    82,310    107,182    41,301    6...\n",
      "2. [table] Research and development expense:   122,389    105,021    236,380    92,801    149,094    47,919    ...\n",
      "3. [table] Research and development expense:   145,500    129,626    246,050    114,604    204,244    54,989   ...\n",
      "4. [table] : • business outlook for 2023 and beyond;...\n",
      "5. [table] : • business outlook for 2024 and beyond;...\n",
      "\n",
      "=== Hybrid Retrieval (Dense + BM25) ===\n",
      "1. [table] ​:  2024   2023   2022  ...\n",
      "2. [table] ​:  2024  2023  2022  2021  2020...\n",
      "3. [table] (in millions):  2024   2023  None None...\n",
      "4. [table] :  2024   2023   Percent Change  None None None...\n",
      "5. [table] :  2024   2023   Actual   ConstantCurrency  None None None None...\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate hybrid search fusion\n",
    "query = \"R&D expense growth 2023 to 2024\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "# Dense retrieval only\n",
    "dense_results = hierarchical_retriever.retrieve(\n",
    "    query=query,\n",
    "    route_info={'is_table_centric': True},\n",
    "    top_k_content=5,\n",
    "    use_hybrid=False\n",
    ")\n",
    "\n",
    "print(\"=== Dense Retrieval Only ===\")\n",
    "for i, result in enumerate(dense_results['content'][:5]):\n",
    "    print(f\"{i+1}. [{result['metadata']['content_type']}] {result['content'][:100]}...\")\n",
    "\n",
    "# Hybrid retrieval (dense + BM25)\n",
    "hybrid_results = hierarchical_retriever.retrieve(\n",
    "    query=query,\n",
    "    route_info={'is_table_centric': True},\n",
    "    top_k_content=5,\n",
    "    use_hybrid=True\n",
    ")\n",
    "\n",
    "print(\"\\n=== Hybrid Retrieval (Dense + BM25) ===\")\n",
    "for i, result in enumerate(hybrid_results['content'][:5]):\n",
    "    print(f\"{i+1}. [{result['metadata']['content_type']}] {result['content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Encoder Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: operating segment revenue contribution 2024\n",
      "\n",
      "=== Reranked Results ===\n",
      "1. [table]\n",
      "   Original: 7.5742, Reranked: -4.1282\n",
      "   Contracted Assets:  Contracted Assets operating segment...\n",
      "\n",
      "2. [table]\n",
      "   Original: 3.1250, Reranked: -4.3758\n",
      "   Contracted Energy:  Contracted Energy operating segment, formerly known as the Contracted Assets operating segment...\n",
      "\n",
      "3. [table]\n",
      "   Original: 0.4222, Reranked: -4.5615\n",
      "   Percentage of Total Revenues:    2023  2022  2021...\n",
      "\n",
      "4. [table]\n",
      "   Original: 2.4149, Reranked: -5.0173\n",
      "   ​:  2024   2023   2022  ...\n",
      "\n",
      "5. [table]\n",
      "   Original: 2.2467, Reranked: -5.0614\n",
      "   June 12, 2024:   August 15, 2024    September 12, 2024   $ 0.75   $ 5,575 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if USE_RERANKING:\n",
    "    query = \"operating segment revenue contribution 2024\"\n",
    "    \n",
    "    # Initial retrieval\n",
    "    initial_results = hierarchical_retriever.retrieve(\n",
    "        query=query,\n",
    "        route_info={'is_table_centric': True},\n",
    "        top_k_content=20,\n",
    "        use_hybrid=True\n",
    "    )\n",
    "    \n",
    "    # Prepare pairs for reranking\n",
    "    pairs = [[query, result['content']] for result in initial_results['content']]\n",
    "    \n",
    "    # Rerank\n",
    "    rerank_scores = cross_encoder.predict(pairs)\n",
    "    \n",
    "    # Sort by rerank scores\n",
    "    reranked_indices = np.argsort(rerank_scores)[::-1]\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"=== Reranked Results ===\")\n",
    "    for i, idx in enumerate(reranked_indices[:5]):\n",
    "        result = initial_results['content'][idx]\n",
    "        original_score = result['score']\n",
    "        rerank_score = rerank_scores[idx]\n",
    "        \n",
    "        print(f\"{i+1}. [{result['metadata']['content_type']}]\")\n",
    "        print(f\"   Original: {original_score:.4f}, Reranked: {rerank_score:.4f}\")\n",
    "        print(f\"   {result['content'][:120]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multi-Query Test Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Retrieval Test Suite ===\n",
      "\n",
      "================================================================================\n",
      "Query: Report the YoY change in R&D expense for 2022 to 2024\n",
      "Route: numeric_table (table-centric: True)\n",
      "\n",
      "Content types retrieved: {'table'}\n",
      "\n",
      "Top 3 results:\n",
      "1. [table] Unknown\n",
      "   ​:  2024   2023   2022  ...\n",
      "2. [table] Unknown\n",
      "   :  2024   2023   Percent Change  None None None...\n",
      "3. [table] Unknown\n",
      "   ​:  2024  2023  2022  2021  2020...\n",
      "\n",
      "================================================================================\n",
      "Query: What is the ratio of long-term debt to equity in 2023?\n",
      "Route: numeric_table (table-centric: True)\n",
      "\n",
      "Content types retrieved: {'table'}\n",
      "\n",
      "Top 3 results:\n",
      "1. [table] Unknown\n",
      "   : II. Investments in debt securities   None...\n",
      "2. [table] Unknown\n",
      "   :  2022   Ratio   2021   Ratio   2020   Ratio  None None None None None None...\n",
      "3. [table] Unknown\n",
      "   :  2023   Ratio   2022   Ratio   2021   Ratio  None None None None None None...\n",
      "\n",
      "================================================================================\n",
      "Query: Which operating segment contributed most to revenue growth?\n",
      "Route: numeric_table (table-centric: True)\n",
      "\n",
      "Content types retrieved: {'table'}\n",
      "\n",
      "Top 3 results:\n",
      "1. [table] Unknown\n",
      "   Contracted Assets:  Contracted Assets operating segment...\n",
      "2. [table] Unknown\n",
      "   Gas Distribution:  Gas Distribution operating segment...\n",
      "3. [table] Unknown\n",
      "   Dominion Energy Virginia:  Dominion Energy Virginia operating segment...\n",
      "\n",
      "================================================================================\n",
      "Query: What are the main business risks?\n",
      "Route: narrative (table-centric: False)\n",
      "\n",
      "Content types retrieved: {'text'}\n",
      "\n",
      "Top 3 results:\n",
      "1. [text] Section 10\n",
      "   2024. Unless otherwise indicated, all store information in this Item 1 is as of January 28, 2023, an...\n",
      "2. [text] Section 10\n",
      "   ain Beneficial Owners and Management and Related Stockholder Matters 42 ITEM 13. Certain Relationshi...\n",
      "3. [text] Section 8\n",
      "   called the “The Power of Inclusion”; business resource groups led by employees; Pentair’s Code of Bu...\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive test queries\n",
    "test_suite = [\n",
    "    {\n",
    "        'query': \"Report the YoY change in R&D expense for 2022 to 2024\",\n",
    "        'expected_content': ['table', 'text'],\n",
    "        'expected_sections': ['Financial Statements', \"Management's Discussion\"]\n",
    "    },\n",
    "    {\n",
    "        'query': \"What is the ratio of long-term debt to equity in 2023?\",\n",
    "        'expected_content': ['table'],\n",
    "        'expected_sections': ['Balance Sheet', 'Financial Statements']\n",
    "    },\n",
    "    {\n",
    "        'query': \"Which operating segment contributed most to revenue growth?\",\n",
    "        'expected_content': ['table', 'text'],\n",
    "        'expected_sections': ['Segment Information', \"Management's Discussion\"]\n",
    "    },\n",
    "    {\n",
    "        'query': \"What are the main business risks?\",\n",
    "        'expected_content': ['text'],\n",
    "        'expected_sections': ['Risk Factors']\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"=== Retrieval Test Suite ===\")\n",
    "\n",
    "for test in test_suite:\n",
    "    query = test['query']\n",
    "    route_info = query_router.route(query)\n",
    "    \n",
    "    results = hierarchical_retriever.retrieve(\n",
    "        query=query,\n",
    "        route_info=route_info,\n",
    "        top_k_sections=3,\n",
    "        top_k_content=5,\n",
    "        use_hybrid=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Route: {route_info['query_type']} (table-centric: {route_info['is_table_centric']})\")\n",
    "    \n",
    "    # Check content types\n",
    "    content_types = [r['metadata']['content_type'] for r in results['content']]\n",
    "    print(f\"\\nContent types retrieved: {set(content_types)}\")\n",
    "    \n",
    "    # Show top results\n",
    "    print(\"\\nTop 3 results:\")\n",
    "    for i, result in enumerate(results['content'][:3]):\n",
    "        meta = result['metadata']\n",
    "        print(f\"{i+1}. [{meta['content_type']}] {meta.get('section', meta.get('section_title', 'N/A'))}\")\n",
    "        print(f\"   {result['content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Retrieval Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Retrieval Statistics ===\n",
      "Total queries tested: 4\n",
      "Avg results per query: 10.00\n",
      "Avg retrieval time: 61.95 ms\n",
      "Content type distribution: {'text': 10, 'table': 30}\n"
     ]
    }
   ],
   "source": [
    "# Calculate retrieval statistics\n",
    "retrieval_stats = {\n",
    "    'total_queries': len(test_suite),\n",
    "    'avg_results_per_query': [],\n",
    "    'content_type_distribution': {'text': 0, 'table': 0},\n",
    "    'avg_retrieval_time': []\n",
    "}\n",
    "\n",
    "import time\n",
    "\n",
    "for test in test_suite:\n",
    "    query = test['query']\n",
    "    route_info = query_router.route(query)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = hierarchical_retriever.retrieve(\n",
    "        query=query,\n",
    "        route_info=route_info,\n",
    "        top_k_content=10\n",
    "    )\n",
    "    retrieval_time = time.time() - start_time\n",
    "    \n",
    "    retrieval_stats['avg_results_per_query'].append(len(results['content']))\n",
    "    retrieval_stats['avg_retrieval_time'].append(retrieval_time)\n",
    "    \n",
    "    for result in results['content']:\n",
    "        content_type = result['metadata']['content_type']\n",
    "        if content_type in retrieval_stats['content_type_distribution']:\n",
    "            retrieval_stats['content_type_distribution'][content_type] += 1\n",
    "\n",
    "print(\"\\n=== Retrieval Statistics ===\")\n",
    "print(f\"Total queries tested: {retrieval_stats['total_queries']}\")\n",
    "print(f\"Avg results per query: {np.mean(retrieval_stats['avg_results_per_query']):.2f}\")\n",
    "print(f\"Avg retrieval time: {np.mean(retrieval_stats['avg_retrieval_time'])*1000:.2f} ms\")\n",
    "print(f\"Content type distribution: {retrieval_stats['content_type_distribution']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Proceed to **05_qa_generation.ipynb** to implement answer generation with the LLM reader and math verification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs582",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
